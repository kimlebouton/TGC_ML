{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L04qs.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimlebouton/TGC_ML/blob/main/L04qs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFrzPlyoikd9"
      },
      "source": [
        "What do you think will happen to the accuracy of training a neural network as the number of layers increases? Try training a neural network for the MNIST data using more layers to see what happens. Speculate as to why you are seeing what you are seeing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ27Nqb8TBKx"
      },
      "source": [
        "# Read in the mnist digit dataset\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import check_random_state\n",
        "import random\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB0MV4C1jCAC"
      },
      "source": [
        "Next, we will divide the data into a training set and test set, randomly selecting 5000 examples for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ2-XGCVTBK3"
      },
      "source": [
        "train_samples = 5000\n",
        "\n",
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=train_samples, test_size=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTpGs2l-kdOs"
      },
      "source": [
        "Now, we will try 10 hidden units in each of 1 to 10 layers, keeping track of the min/mean/max accuracy of models at each number of layers over ten runs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFoZESbCupY3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bcd8e80b-764d-4472-c55d-9435d87f7a2e"
      },
      "source": [
        "reps = 10\n",
        "for i in range(1,11):\n",
        "  nhidden = i*[100]\n",
        "  accsum,accmin,accmax = 0.0,1.0,0.0\n",
        "  for r in range(reps):\n",
        "    clf = MLPClassifier(hidden_layer_sizes=nhidden, max_iter = 10000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    score = clf.score(X_test, y_test)\n",
        "    accsum += score\n",
        "    accmin = min(accmin, score)\n",
        "    accmax = max(accmax, score)\n",
        "  print(i, accmin, accsum/reps, accmax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0.8696 0.88229 0.8923\n",
            "2 0.8584 0.8683400000000001 0.878\n",
            "3 0.8442 0.85788 0.8673\n",
            "4 0.8638 0.8722900000000001 0.8782\n",
            "5 0.8817 0.88993 0.9004\n",
            "6 0.8868 0.8956899999999999 0.9046\n",
            "7 0.8987 0.9082800000000001 0.9179\n",
            "8 0.9074 0.9196899999999999 0.9272\n",
            "9 0.891 0.9213099999999999 0.936\n",
            "10 0.9117 0.9243399999999999 0.9389\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}